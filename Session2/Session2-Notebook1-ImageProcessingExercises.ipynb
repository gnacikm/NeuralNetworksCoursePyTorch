{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir0woaGccujW"
   },
   "source": [
    "# Image Processing Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dMuEiDKaEiA9"
   },
   "source": [
    "# GPU in colab\n",
    "First, you'll need to enable GPUs for the notebook:\n",
    "*   Navigate to Editâ†’Notebook Settings\n",
    "*   select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11117,
     "status": "ok",
     "timestamp": 1737302965566,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "kiL_AutGnVKO",
    "outputId": "fa945143-f58f-4c69-85c6-0dea481bb1a1"
   },
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8914,
     "status": "ok",
     "timestamp": 1737302974476,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "K2J6c_RMDy-n",
    "outputId": "9642ff26-72b3-4d89-96e4-c777f0d3242a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "print(f\"Found GPU at: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1737302974476,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "buS9MDnpEXtP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import drive, files\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16773,
     "status": "ok",
     "timestamp": 1737302991247,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "wfFhCSF0Rin3"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-s7BimmObltf"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "a) Load and preprocess CIFAR10 Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5F7X5EoHz2xC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsm-Y1kwZiDy"
   },
   "source": [
    "b) Set up the neural network model without the MAGIC LAYERS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N1PRk15Az30o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSAFFTd6Zn-M"
   },
   "source": [
    "c) Compile the model and fit the data to the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4i0W1f7z7Vp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DX5F4tg1er4r"
   },
   "source": [
    "d) Plot the accuracy and loss curves, also view it on tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AfGmHYrnz9ZO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pObVcT9Jeqgc"
   },
   "source": [
    "e) Evaluate the model on the test data and compare your scores with the GUIDE notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhnsciIpz_ji"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0pNJ4sBcF5u"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "a) Mount your google drive:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26410,
     "status": "ok",
     "timestamp": 1737303084849,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "bYmGx5fCeyNy",
    "outputId": "870bfa7b-a60b-4dba-f6bb-177599a65aa0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQ0bHwhmetBT"
   },
   "source": [
    "b)\n",
    "Data Source FER.zip: https://drive.google.com/file/d/1CC8sSO8AJLmx2dgsGaYBVCrM8lzrtUDG/view?usp=sharing\n",
    "\n",
    "Upload the FER.zip file to your COLAB files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Make sure that the upload has finished, check the circular progress bar.\n",
    "c). Unzip the files to your google drive location by running the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1737303121682,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "RNq2Zsnee-Mi"
   },
   "outputs": [],
   "source": [
    "!mkdir  \"/content/drive/My Drive/Colab Notebooks/FER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212930,
     "status": "ok",
     "timestamp": 1737303337932,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "2k4nPkImfbXL",
    "outputId": "e827cd61-a3f0-4cb5-a5ea-b73116196fe0"
   },
   "outputs": [],
   "source": [
    "# need to run it only once!!!!!!\n",
    "!unzip -FF \"/content/FER.zip\" -d \"/content/drive/My Drive/Colab Notebooks/FER\" # need to run it only once!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQORcxrnetHR"
   },
   "source": [
    "c) Set up the dataset from directory by running the following cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1737303343733,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "asBGLLM6V-fO"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = (48, 48)\n",
    "train_dir = \"/content/drive/My Drive/Colab Notebooks/FER/train\"\n",
    "test_dir = \"/content/drive/My Drive/Colab Notebooks/FER/test\"\n",
    "str_labels = [\"happy\", \"neutral\", \"sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 970,
     "status": "ok",
     "timestamp": 1737303541569,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "767XalafWdIT"
   },
   "outputs": [],
   "source": [
    "def get_data_transformation() -> transforms.Compose:\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            transforms.Grayscale(),  # Convert to grayscale\n",
    "            transforms.Resize(IMAGE_SIZE),  # Resize to target size\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737303544299,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "CeYYHumdV8Gz"
   },
   "outputs": [],
   "source": [
    "def load_fer_data(batch_size: int, validation_split: float) -> tuple:\n",
    "    transform = get_data_transformation()\n",
    "\n",
    "    # Load train dataset\n",
    "    full_train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "\n",
    "    # Load test dataset\n",
    "    test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "    # Calculate the sizes of each dataset\n",
    "    train_size: int = int((1 - validation_split) * len(full_train_dataset))\n",
    "    val_size: int = len(full_train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(\n",
    "        full_train_dataset, [train_size, val_size]\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2336,
     "status": "ok",
     "timestamp": 1737304018150,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "6bpdXCwaWv7J"
   },
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_fer_data(BATCH_SIZE, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1737304019865,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "_s18psz1Y0UC"
   },
   "outputs": [],
   "source": [
    "vis_train_dataset, _, _ = load_fer_data(BATCH_SIZE, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TWF0lYvlXrS"
   },
   "source": [
    "d) Visualise the images by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 982,
     "status": "ok",
     "timestamp": 1737304023287,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "dpxYvhWBXJ4b"
   },
   "outputs": [],
   "source": [
    "def visualize_pytorch_dataset(\n",
    "    data_loader: DataLoader,\n",
    "    str_labels: list[str],\n",
    "    num_of_imgs: int = 4,\n",
    "    nrows: int = 2,\n",
    "    ncols: int = 2,\n",
    "):\n",
    "    # Get a single batch of data\n",
    "    batch = next(iter(data_loader))\n",
    "    images, labels = batch\n",
    "    images = images.numpy()  # Convert to numpy for visualization\n",
    "    labels = labels.numpy()  # Convert labels to numpy\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5, 10))\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if k >= num_of_imgs:  # Stop if we've visualized enough images\n",
    "                break\n",
    "            image = images[k].squeeze(0)  # Remove channel dimension if grayscale\n",
    "            label = str_labels[labels[k]]  # Get the class label\n",
    "\n",
    "            axes[i][j].imshow(image, cmap=\"gray\")\n",
    "            axes[i][j].set_title(label, fontsize=15)\n",
    "            axes[i][j].axis(\"off\")\n",
    "            k += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1737304030463,
     "user": {
      "displayName": "Michal Gnacik",
      "userId": "05693853346063217104"
     },
     "user_tz": 0
    },
    "id": "o0HEqEKsXV-C",
    "outputId": "74553919-63c1-47bf-9c9a-d133f3be437b"
   },
   "outputs": [],
   "source": [
    "visualize_pytorch_dataset(vis_train_dataset, str_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9p0HWHN_X71D"
   },
   "source": [
    "3. Create a neural network model (with MAGIC LAYERS) and fit it to the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLJZcyxn0j4P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GFTOglZYUqy"
   },
   "source": [
    "4. Make predictions on the test data set and display your predictions versus the photos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gywate5NnH1u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
